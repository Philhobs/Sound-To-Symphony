{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f900d0-192c-4dac-9eb5-92724d99a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c5db9f-5f2f-42bc-a152-341aa4383753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Notes\n",
      "['G', 'D']\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import pydub.scipy_effects\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft\n",
    "\n",
    "\n",
    "from utils import (\n",
    "    frequency_spectrum,\n",
    "    calculate_distance,\n",
    "    classify_note_attempt_1,\n",
    "    classify_note_attempt_2,\n",
    "    classify_note_attempt_3,\n",
    ")\n",
    "from utils import frequency_spectrum, calculate_distance, classify_note_attempt_1, classify_note_attempt_2, classify_note_attempt_3\n",
    "\n",
    "def main(file, note_file=None, note_starts_file=None, plot_starts=False, plot_fft_indices=[]):\n",
    "    # If a note file and/or actual start times are supplied read them in\n",
    "    actual_starts = []\n",
    "    if note_starts_file:\n",
    "        with open(note_starts_file) as f:\n",
    "            for line in f:\n",
    "                actual_starts.append(float(line.strip()))\n",
    "\n",
    "    actual_notes = []\n",
    "    if note_file:\n",
    "        with open(note_file) as f:\n",
    "            for line in f:\n",
    "                actual_notes.append(line.strip())\n",
    "\n",
    "    song = AudioSegment.from_file(file)\n",
    "    song = song.high_pass_filter(80, order=4)\n",
    "\n",
    "    starts = predict_note_starts(song, plot_starts, actual_starts)\n",
    "\n",
    "    predicted_notes = predict_notes(song, starts, actual_notes, plot_fft_indices)\n",
    "\n",
    "    print(\"\")\n",
    "    if actual_notes:\n",
    "        print(\"Actual Notes\")\n",
    "        print(actual_notes)\n",
    "    print(\"Predicted Notes\")\n",
    "    print(predicted_notes)\n",
    "\n",
    "    if actual_notes:\n",
    "        lev_distance = calculate_distance(predicted_notes, actual_notes)\n",
    "        print(\"Levenshtein distance: {}/{}\".format(lev_distance, len(actual_notes)))\n",
    "\n",
    "\n",
    "def predict_note_starts(song, plot, actual_starts):\n",
    "    # Size of segments (song spliting) calculated by volume\n",
    "    SEGMENT_MS = 50\n",
    "    # Minimum volume necessary to be considered a note\n",
    "    VOLUME_THRESHOLD = -35\n",
    "    # The increase from one sample to the next required to be considered a note\n",
    "    EDGE_THRESHOLD = 5\n",
    "    # Throw out any additional notes found in this window\n",
    "    MIN_MS_BETWEEN = 100\n",
    "\n",
    "    # Filter out lower frequencies to reduce noise\n",
    "    song = song.high_pass_filter(80, order=4)\n",
    "    # dBFS is decibels relative to the maximum possible loudness\n",
    "    volume = [segment.dBFS for segment in song[::SEGMENT_MS]]\n",
    "\n",
    "    predicted_starts = []\n",
    "    for i in range(1, len(volume)):\n",
    "        if volume[i] > VOLUME_THRESHOLD and volume[i] - volume[i - 1] > EDGE_THRESHOLD:\n",
    "            ms = i * SEGMENT_MS\n",
    "            # Ignore any too close together\n",
    "            if len(predicted_starts) == 0 or ms - predicted_starts[-1] >= MIN_MS_BETWEEN:\n",
    "                predicted_starts.append(ms)\n",
    "\n",
    "    # If actual note start times are provided print a comparison\n",
    "    if len(actual_starts) > 0:\n",
    "        print(\"Approximate actual note start times ({})\".format(len(actual_starts)))\n",
    "        print(\" \".join([\"{:5.2f}\".format(s) for s in actual_starts]))\n",
    "        print(\"Predicted note start times ({})\".format(len(predicted_starts)))\n",
    "        print(\" \".join([\"{:5.2f}\".format(ms / 1000) for ms in predicted_starts]))\n",
    "\n",
    "    # Plot the volume over time (sec)\n",
    "    if plot:\n",
    "        x_axis = np.arange(len(volume)) * (SEGMENT_MS / 1000)\n",
    "        plt.plot(x_axis, volume)\n",
    "\n",
    "        # predicted note starts and actual note starts\n",
    "        for s in actual_starts:\n",
    "            plt.axvline(x=s, color=\"r\", linewidth=0.5, linestyle=\"-\")\n",
    "        for ms in predicted_starts:\n",
    "            plt.axvline(x=(ms / 1000), color=\"g\", linewidth=0.5, linestyle=\":\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return predicted_starts\n",
    "\n",
    "\n",
    "def predict_notes(song, starts, actual_notes, plot_fft_indices):\n",
    "    predicted_notes = []\n",
    "\n",
    "    for i, start in enumerate(starts):\n",
    "        sample_from = start + 50\n",
    "        sample_to = start + 550\n",
    "        if i < len(starts) - 1:\n",
    "            sample_to = min(starts[i + 1], sample_to)\n",
    "        segment = song[sample_from:sample_to]\n",
    "        freqs, freq_magnitudes = frequency_spectrum(segment)\n",
    "\n",
    "        predicted = classify_note_attempt_3(freqs, freq_magnitudes)\n",
    "        predicted_notes.append(predicted or \"No identification\")\n",
    "\n",
    "    return predicted_notes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # WAV file - here we should put the path, where the output note of our model should go through to display the note it generated\n",
    "    file_path = '/Users/phila/code/Philhobs/Sound-To-Symphony/raw_data/nsynth-train2/audio/brass_acoustic_063-062-025.wav'\n",
    "    \n",
    "    main(file_path, note_file=None, note_starts_file=None, plot_starts=False, plot_fft_indices=[])\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f91185-88ba-4433-acb6-4f5a40acfa93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26a866-ab06-4ede-b039-0ffc170dc658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
